{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c2441bc-57c0-491a-b596-3e46b22500eb",
   "metadata": {},
   "source": [
    "# IMDb Data Scraping Project\n",
    "\n",
    "## Erin Schultz & Reed Ulses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00751e-ef98-49ad-a797-fb751f747a90",
   "metadata": {},
   "source": [
    "Scraping the IMDb website (https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2021-12-31&countries=US&count=250&sort=release_date,desc) for the title, release year, and IMDb rating for these movies to eventually merge with a Kaggle dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0d40883b-eccf-43f0-9300-af4d89d6125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this first and wait for it to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6d147e27-ad01-4efb-ab6e-8d74a23ddb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException \n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "281a1c5e-00e3-45c0-8ec2-4960ac8a3653",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this second and wait for it to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf79b504-e4c8-41f4-bceb-147c70ea9102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scroll from the top to the bottom of the web page\n",
    "def random_scroll(browser, total_wait_tie):\n",
    "    # browser.execute_script(\"window.focus();\")\n",
    "    \n",
    "    # get the total height of the page\n",
    "    total_height = browser.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    # number of steps to scroll (you can adjust this number)\n",
    "    scroll_steps = random.randint(3, 10) # randomize how many scroll steps we will use\n",
    "    \n",
    "    # calculate the height to scroll on each step\n",
    "    scroll_increment = total_height // scroll_steps\n",
    "\n",
    "    # calculate the total time available for scrolling each step\n",
    "    time_per_step = total_wait_time / scroll_steps\n",
    "    \n",
    "    # random scrolling across time\n",
    "    for step in range(scroll_steps):\n",
    "        # scroll by the increment (dividing total height by number of steps)\n",
    "        browser.execute_script(f\"window.scrollBy(0, {scroll_increment});\")\n",
    "        \n",
    "        # random wait time between scrolls to simulate varying speed\n",
    "        random_wait = random.uniform(0.5 * time_per_step, 1.5 * time_per_step)  # randomize the wait within a range\n",
    "        time.sleep(random_wait)\n",
    "        \n",
    "    # final scroll to make sure you are at the very bottom (in case it didn't exactly match)\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c59da0b-1c61-44ff-a040-a4571dea8b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this third and wait for it to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7cf16c42-f462-41a3-94a2-47a4a0420fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_movies(browser):\n",
    "    print(\"scraping data\")\n",
    "    movies = browser.find_elements(By.XPATH, \"//div[@class='ipc-metadata-list-summary-item__c']\")\n",
    " \n",
    "    for movie in movies:\n",
    "        # TITLE\n",
    "        title_elements = movie.find_elements(By.XPATH, \".//h3[@class='ipc-title__text']\")\n",
    "        #title_elements = movie.find_elements(By.CLASS_NAME, 'ipc-title__text')\n",
    "        for title in title_elements:\n",
    "            movie_title = title.text\n",
    "\n",
    "        # YEAR\n",
    "        year_elements = movie.find_elements(By.XPATH, \".//span[@class='sc-5bc66c50-6 OOdsw dli-title-metadata-item' and contains(text(), '20')]\")\n",
    "        if year_elements:  # Check if year_elements is not empty\n",
    "            movie_year = year_elements[0].text  # Use the first matching year\n",
    "        else:\n",
    "            movie_year = \"\"  # Default to an empty string if no year is found\n",
    "\n",
    "        # RATING\n",
    "        imdb_elements = movie.find_elements(By.XPATH, \".//span[@class='ipc-rating-star--rating']\")\n",
    "        if imdb_elements:  # Check if year_elements is not empty\n",
    "            imdb_ratings = imdb_elements[0].text  # Use the first matching year\n",
    "        else:\n",
    "            imdb_ratings = \"\"  # Default to an empty string if no year is found    \n",
    "\n",
    "        #save the data as a list of dictionaries\n",
    "        all_movies.append({\n",
    "            \"title\": movie_title,\n",
    "            \"year\": movie_year,\n",
    "            \"imdb_ratings\": imdb_ratings\n",
    "        })\n",
    "       \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "aa24723e-3e37-4a0b-ba11-d7aaac575cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this fourth and wait for it to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d9806ab9-bc8c-40b6-8a21-976a2911892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(loop, all_movies):\n",
    "    df_name = f\"imdb_{loop}_df\"\n",
    "    csv_name = f\"imdb_{loop}.csv\"\n",
    "\n",
    "    # convert lists to a pandas datadataframe\n",
    "    print(\"building the dataframe\")\n",
    "    df_name = pd.DataFrame(all_movies)\n",
    "    \n",
    "    # perist data in a CSV file\n",
    "    print(f\"saving the data as {csv_name}\")\n",
    "    df_name.to_csv(csv_name, header=True, index=False, sep=\",\", encoding='utf-8')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d59e29f6-4942-4dc8-ac7a-ce584a610499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this fifth and wait for it to complete. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ce9c56aa-fd0e-4fbd-949e-ffaabedcc573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Selenium web driver (Chrome)\n",
    "browser = webdriver.Chrome()\n",
    "# browser = webdriver.Chrome(service=Service(ChromeDriverManager().install())) # this occasionally causes \"Status code was: -9\" error.\n",
    "\n",
    "url = 'https://www.imdb.com/search/title/?title_type=feature&release_date=2000-01-01,2021-12-31&countries=US&count=250&sort=release_date,desc'\n",
    "\n",
    "# navigate to the web page using the URL\n",
    "browser.get(url)\n",
    "\n",
    "browser.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "425cba24-0d6b-47de-a305-4bb5aa7dc75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this sixth. It is doing all the work. \n",
    "# Don't assume it is hung unless it hasn't moved or added a new message for over 4 minutes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c6aa965e-5f3c-4ab2-a9be-58d352d089b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scrolling down the page\n",
      "loop 1 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_1.csv\n",
      "scraped 250 of 89421 records\n",
      "0.0% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 2 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_2.csv\n",
      "scraped 500 of 89421 records\n",
      "0.01% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 3 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_3.csv\n",
      "scraped 750 of 89421 records\n",
      "0.01% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 4 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_4.csv\n",
      "scraped 999 of 89421 records\n",
      "0.01% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 5 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_5.csv\n",
      "scraped 1249 of 89421 records\n",
      "0.01% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 6 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_6.csv\n",
      "scraped 1499 of 89421 records\n",
      "0.02% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 7 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_7.csv\n",
      "scraped 1749 of 89421 records\n",
      "0.02% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 8 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_8.csv\n",
      "scraped 1999 of 89421 records\n",
      "0.02% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 9 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_9.csv\n",
      "scraped 2249 of 89421 records\n",
      "0.03% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 10 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_10.csv\n",
      "scraped 2499 of 89421 records\n",
      "0.03% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 11 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_11.csv\n",
      "scraped 2748 of 89421 records\n",
      "0.03% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 12 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_12.csv\n",
      "scraped 2998 of 89421 records\n",
      "0.03% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 13 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_13.csv\n",
      "scraped 3247 of 89421 records\n",
      "0.04% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 14 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_14.csv\n",
      "scraped 3497 of 89421 records\n",
      "0.04% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 15 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_15.csv\n",
      "scraped 3746 of 89421 records\n",
      "0.04% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 16 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_16.csv\n",
      "scraped 3996 of 89421 records\n",
      "0.04% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 17 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_17.csv\n",
      "scraped 4246 of 89421 records\n",
      "0.05% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 18 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_18.csv\n",
      "scraped 4496 of 89421 records\n",
      "0.05% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 19 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_19.csv\n",
      "scraped 4746 of 89421 records\n",
      "0.05% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 20 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_20.csv\n",
      "scraped 4996 of 89421 records\n",
      "0.06% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 21 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_21.csv\n",
      "scraped 5246 of 89421 records\n",
      "0.06% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 22 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_22.csv\n",
      "scraped 5496 of 89421 records\n",
      "0.06% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 23 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_23.csv\n",
      "scraped 5746 of 89421 records\n",
      "0.06% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 24 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_24.csv\n",
      "scraped 5996 of 89421 records\n",
      "0.07% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 25 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_25.csv\n",
      "scraped 6246 of 89421 records\n",
      "0.07% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 26 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_26.csv\n",
      "scraped 6496 of 89421 records\n",
      "0.07% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 27 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_27.csv\n",
      "scraped 6746 of 89421 records\n",
      "0.08% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 28 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_28.csv\n",
      "scraped 6996 of 89421 records\n",
      "0.08% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 29 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_29.csv\n",
      "scraped 7245 of 89421 records\n",
      "0.08% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 30 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_30.csv\n",
      "scraped 7495 of 89421 records\n",
      "0.08% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 31 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_31.csv\n",
      "scraped 7745 of 89421 records\n",
      "0.09% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 32 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_32.csv\n",
      "scraped 7995 of 89421 records\n",
      "0.09% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 33 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_33.csv\n",
      "scraped 8245 of 89421 records\n",
      "0.09% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 34 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_34.csv\n",
      "scraped 8495 of 89421 records\n",
      "0.1% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 35 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_35.csv\n",
      "scraped 8745 of 89421 records\n",
      "0.1% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 36 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_36.csv\n",
      "scraped 8995 of 89421 records\n",
      "0.1% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 37 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_37.csv\n",
      "scraped 9245 of 89421 records\n",
      "0.1% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 38 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_38.csv\n",
      "scraped 9495 of 89421 records\n",
      "0.11% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 39 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_39.csv\n",
      "scraped 9745 of 89421 records\n",
      "0.11% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 40 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_40.csv\n",
      "scraped 9995 of 89421 records\n",
      "0.11% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 41 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_41.csv\n",
      "scraped 10245 of 89421 records\n",
      "0.11% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 42 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_42.csv\n",
      "scraped 10495 of 89421 records\n",
      "0.12% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 43 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_43.csv\n",
      "scraped 10745 of 89421 records\n",
      "0.12% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 44 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_44.csv\n",
      "scraped 10995 of 89421 records\n",
      "0.12% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 45 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_45.csv\n",
      "scraped 11245 of 89421 records\n",
      "0.13% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 46 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_46.csv\n",
      "scraped 11494 of 89421 records\n",
      "0.13% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 47 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_47.csv\n",
      "scraped 11744 of 89421 records\n",
      "0.13% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 48 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_48.csv\n",
      "scraped 11994 of 89421 records\n",
      "0.13% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 49 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_49.csv\n",
      "scraped 12244 of 89421 records\n",
      "0.14% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 50 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_50.csv\n",
      "scraped 12494 of 89421 records\n",
      "0.14% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 51 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_51.csv\n",
      "scraped 12744 of 89421 records\n",
      "0.14% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 52 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_52.csv\n",
      "scraped 12994 of 89421 records\n",
      "0.15% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 53 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n",
      "calling function to create dataframe and save CSV\n",
      "building the dataframe\n",
      "saving the data as imdb_53.csv\n",
      "scraped 13244 of 89421 records\n",
      "0.15% complete\n",
      "scrolling up so the '250 more' button is in view\n",
      "clicked the 'next' button using JavaScript\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n",
      "scrolling down the page\n",
      "loop 54 of 358 loops\n",
      "calling function to scrape movies\n",
      "scraping data\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m all_movies \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling function to scrape movies\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m scrape_movies(browser)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling function to create dataframe and save CSV\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m save_data(loop, all_movies)\n",
      "Cell \u001b[0;32mIn[76], line 13\u001b[0m, in \u001b[0;36mscrape_movies\u001b[0;34m(browser)\u001b[0m\n\u001b[1;32m     10\u001b[0m     movie_title \u001b[38;5;241m=\u001b[39m title\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# YEAR\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m year_elements \u001b[38;5;241m=\u001b[39m movie\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mXPATH, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.//span[@class=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msc-5bc66c50-6 OOdsw dli-title-metadata-item\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and contains(text(), \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m year_elements:  \u001b[38;5;66;03m# Check if year_elements is not empty\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     movie_year \u001b[38;5;241m=\u001b[39m year_elements[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext  \u001b[38;5;66;03m# Use the first matching year\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webelement.py:439\u001b[0m, in \u001b[0;36mWebElement.find_elements\u001b[0;34m(self, by, value)\u001b[0m\n\u001b[1;32m    436\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[1;32m    437\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 439\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute(Command\u001b[38;5;241m.\u001b[39mFIND_CHILD_ELEMENTS, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124musing\u001b[39m\u001b[38;5;124m\"\u001b[39m: by, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m: value})[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent\u001b[38;5;241m.\u001b[39mexecute(command, params)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/webdriver.py:352\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m    350\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m--> 352\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:306\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[0;34m(self, command, params)\u001b[0m\n\u001b[1;32m    304\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[1;32m    305\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(command_info[\u001b[38;5;241m0\u001b[39m], url, body\u001b[38;5;241m=\u001b[39mdata)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/selenium/webdriver/remote/remote_connection.py:326\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[0;34m(self, method, url, body)\u001b[0m\n\u001b[1;32m    323\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[0;32m--> 326\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders)\n\u001b[1;32m    327\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[1;32m    328\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/_request_methods.py:144\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[1;32m    137\u001b[0m         method,\n\u001b[1;32m    138\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[1;32m    142\u001b[0m     )\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[1;32m    145\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m    146\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/_request_methods.py:279\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[0;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[1;32m    275\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[1;32m    277\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/poolmanager.py:443\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    441\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 443\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, u\u001b[38;5;241m.\u001b[39mrequest_uri, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    445\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loop = 1\n",
    "# all_movies = []\n",
    "\n",
    "while True:\n",
    "    browser.execute_script(\"window.focus();\")\n",
    "\n",
    "    # generating a random wait time\n",
    "    total_wait_time = random.uniform(15, 30)\n",
    "\n",
    "    # scrolling down the page\n",
    "    print(\"scrolling down the page\")\n",
    "    random_scroll(browser, total_wait_time)\n",
    "\n",
    "    # there are 89421 records displayed 250 at a time\n",
    "    print(f\"loop {loop} of 358 loops\")\n",
    "        \n",
    "    ####################\n",
    "    ## Put your scraping code, or a call to your scraping function in here.\n",
    "    # when the counter is on the even thousand, scrape and save the movies\n",
    "\n",
    "    # create an empty all_movies list on each loop so there are not duplicates\n",
    "    all_movies = []\n",
    "    \n",
    "    print(\"calling function to scrape movies\")\n",
    "    scrape_movies(browser)\n",
    "    print(\"calling function to create dataframe and save CSV\")\n",
    "    save_data(loop, all_movies)\n",
    "\n",
    "    total_records = 89421\n",
    "    print(f\"scraped {len(all_movies)} of {total_records} records\")\n",
    "    print(f\"{round(len(all_movies)/total_records, 2)}% complete\")\n",
    "    \n",
    "    ####################\n",
    "\n",
    "    print(\"scrolling up so the '250 more' button is in view\")\n",
    "    # scroll up by 250 pixels so the '250 more' link is in view\n",
    "    time.sleep(3)\n",
    "    browser.execute_script(\"window.scrollBy(0, -250);\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "    try:\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # look for the '250 more' button by the 'class' attribute\n",
    "        next_button = browser.find_element(By.CSS_SELECTOR, 'span[class=\"ipc-see-more__text\"]')\n",
    "        \n",
    "        # scroll the button into view\n",
    "        browser.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "\n",
    "        # waiting after it is scrolled into view to allow overlay to disappear\n",
    "        time.sleep(total_wait_time)\n",
    "\n",
    "        # clicking the button using execute_script\n",
    "        print(\"clicked the 'next' button using JavaScript\")\n",
    "        print(\"-\" * 65)\n",
    "        print(\"\\n\")\n",
    "        browser.execute_script(\"arguments[0].click();\", next_button)  # Using JavaScript to click the button\n",
    "        time.sleep(10)\n",
    "\n",
    "        loop = loop + 1\n",
    "\n",
    "    except NoSuchElementException:\n",
    "        ####################\n",
    "        ## Put your scraping code, or a call to your scraping function in here.\n",
    "        # when the counter is on the even thousand, scrape and save the movies\n",
    "\n",
    "        print(\"calling function to scrape movies\")\n",
    "        scrape_movies(browser)\n",
    "        print(\"calling function to create dataframe and save CSV\")\n",
    "        save_data(loop, all_movies)\n",
    "        \n",
    "        ####################\n",
    "\n",
    "        # Handle the case where the '250 more' button is not found\n",
    "        print(\"No more 'Next' button found. Stopping scrape.\")\n",
    "        break  # This correctly breaks out of the `while` loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b555e14f-8807-4d34-879e-6f1b7702b651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>imdb_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. Oh My Darling</td>\n",
       "      <td>2021</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2. Blueberry</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3. H.P. Lovecraft's Witch House</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4. Malibu Road</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5. Apache Leap</td>\n",
       "      <td>2021</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6. Not Broken</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7. Megaboa</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8. The American Connection</td>\n",
       "      <td>2021</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9. COVID-19: Invasion</td>\n",
       "      <td>2021</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10. Riptide</td>\n",
       "      <td>2021</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11. Fountaine and the Vengeful Nun Who Wouldn'...</td>\n",
       "      <td>2021</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12. A Haunting in Ravenwood</td>\n",
       "      <td>2021</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13. Mouse</td>\n",
       "      <td>2021</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14. Witch</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15. The Girl Behind the Door</td>\n",
       "      <td>2021</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  year imdb_ratings\n",
       "0                                    1. Oh My Darling  2021          5.8\n",
       "1                                        2. Blueberry  2021          6.0\n",
       "2                     3. H.P. Lovecraft's Witch House  2021          2.6\n",
       "3                                      4. Malibu Road  2021          4.5\n",
       "4                                      5. Apache Leap  2021             \n",
       "5                                       6. Not Broken  2021          6.1\n",
       "6                                          7. Megaboa  2021          2.7\n",
       "7                          8. The American Connection  2021          6.8\n",
       "8                               9. COVID-19: Invasion  2021          2.0\n",
       "9                                         10. Riptide  2021          4.2\n",
       "10  11. Fountaine and the Vengeful Nun Who Wouldn'...  2021          5.0\n",
       "11                        12. A Haunting in Ravenwood  2021          5.1\n",
       "12                                          13. Mouse  2021          7.0\n",
       "13                                          14. Witch  2021          8.6\n",
       "14                       15. The Girl Behind the Door  2021          7.1"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df=pd.DataFrame(all_movies)\n",
    "movies_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "76a89a03-c28f-48ac-9190-3a1123dfa6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69966958-879f-4725-87cb-c63dcd711d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "all_movies.to_csv('imdb_scraped.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
